{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8428ba9a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4562a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was needed to download files from repo\n",
    "\n",
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "# !git clone https://github.com/pytorch/vision.git\n",
    "# !cd vision\n",
    "# !git checkout v0.3.0\n",
    "\n",
    "# !cp references/detection/utils.py ../\n",
    "# !cp references/detection/transforms.py ../\n",
    "# !cp references/detection/coco_eval.py ../\n",
    "# !cp references/detection/engine.py ../\n",
    "# !cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8809d0c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ead2de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.coco as fouc\n",
    "from fiftyone.core.labels import Detection\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import utils\n",
    "import train\n",
    "from train import train_one_epoch, evaluate\n",
    "import transforms\n",
    "import DatasetLoaders\n",
    "importlib.reload(DatasetLoaders)\n",
    "from DatasetLoaders import HRSIDDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc47deb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train' from '/home/k3vinli/ENEE439/Capstone/train.py'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(transforms)\n",
    "importlib.reload(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbcaff5c",
   "metadata": {},
   "source": [
    "# loading data into fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c02744d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "name = \"HRSID\"\n",
    "if name in fo.list_datasets():\n",
    "    dataset_traintest = fo.load_dataset(name)\n",
    "else:\n",
    "    dataset_dir = os.path.abspath(\"Datasets/HRSID\")\n",
    "    # The type of the dataset being imported\n",
    "    dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "    dataset_traintest = fo.Dataset.from_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=dataset_type,\n",
    "        name=name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f0d4b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"HRSID_train\"\n",
    "if name in fo.list_datasets():\n",
    "    dataset_train = fo.load_dataset(name)\n",
    "else:\n",
    "    dataset_dir = os.path.abspath(\"Datasets/HRSID\")\n",
    "    label_path = os.path.abspath(\"Datasets/HRSID/annotations/train2017.json\")\n",
    "    # The type of the dataset being imported\n",
    "    dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "    dataset_train = fo.Dataset.from_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=dataset_type,\n",
    "        name=name,\n",
    "        labels_path=label_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b8e7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"HRSID_test\"\n",
    "if name in fo.list_datasets():\n",
    "    dataset_test = fo.load_dataset(name)\n",
    "else:\n",
    "    dataset_dir = os.path.abspath(\"Datasets/HRSID\")\n",
    "    label_path = os.path.abspath(\"Datasets/HRSID/annotations/test2017.json\")\n",
    "    # The type of the dataset being imported\n",
    "    dataset_type = fo.types.COCODetectionDataset\n",
    "\n",
    "    dataset_test = fo.Dataset.from_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=dataset_type,\n",
    "        name=name,\n",
    "        labels_path=label_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f1b3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.compute_metadata()\n",
    "dataset_test.compute_metadata()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e49c0e41",
   "metadata": {},
   "source": [
    "# explore fiftyone useage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e82a450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ImageMetadata: {\n",
       "    'size_bytes': None,\n",
       "    'mime_type': None,\n",
       "    'width': 800,\n",
       "    'height': 800,\n",
       "    'num_channels': None,\n",
       "}>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = dataset_train.values(\"filepath\")\n",
    "sample = dataset_train[paths[1]]\n",
    "sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94472932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "62d3b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(paths[1]).convert(\"RGB\")\n",
    "detections = sample[\"detections\"].detections\n",
    "segmentations = sample[\"segmentations\"].detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40cf5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset_train.distinct(\"%s.detections.label\" % \"segmentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7122423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a993ae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ship': 0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map_rev = {c: i for i, c in enumerate(classes)}\n",
    "labels_map_rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4a1e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in segmentations:\n",
    "    category_id=labels_map_rev[det.label]\n",
    "    coco_obj=fouc.COCOObject.from_label(det, sample.metadata, category_id=category_id)\n",
    "    x,y,w,h=coco_obj.bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4eadd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [coco_obj.segmentation], dtype=torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca678797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fiftyone.core.labels.Detection'>\n",
      "frame size (800, 800)\n",
      "detection: <Detection: {\n",
      "    'id': '64422a7ba776879d966a5afd',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'ship',\n",
      "    'bounding_box': [0.29625, 0.09875, 0.0525, 0.01],\n",
      "    'mask': array([[False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False, False, False, False, False,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True, False, False, False, False],\n",
      "           [False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True, False],\n",
      "           [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True, False],\n",
      "           [False, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True, False, False],\n",
      "           [False, False, False, False, False,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True, False, False, False, False],\n",
      "           [False, False, False, False, False, False, False, False,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "            False, False, False, False, False, False],\n",
      "           [False, False, False, False, False, False, False, False, False,\n",
      "             True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "            False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False,  True,  True,  True,  True, False, False,\n",
      "            False, False, False, False, False, False],\n",
      "           [False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False, False, False, False, False, False, False,\n",
      "            False, False, False, False, False, False]]),\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "    'iscrowd': 0,\n",
      "}>\n",
      "segmentation: <Segmentation: {\n",
      "    'id': '64424a99a776879d966a9148',\n",
      "    'tags': [],\n",
      "    'mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "           [0, 0, 0, ..., 0, 0, 0],\n",
      "           [0, 0, 0, ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0, ..., 0, 0, 0],\n",
      "           [0, 0, 0, ..., 0, 0, 0],\n",
      "           [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
      "    'mask_path': None,\n",
      "}>\n",
      "full img 255\n"
     ]
    }
   ],
   "source": [
    "sample = dataset_test.first()\n",
    "frame_size = (sample.metadata[\"width\"], sample.metadata[\"height\"])\n",
    "detection = sample[\"segmentations\"][\"detections\"][0]\n",
    "\n",
    "segmentation = detection.to_segmentation(frame_size=frame_size)\n",
    "full_img_mask = segmentation.mask\n",
    "print(type(detection))\n",
    "print(\"frame size\", frame_size)\n",
    "print(\"detection:\", detection)\n",
    "print(\"segmentation:\", segmentation)\n",
    "print(\"full img\", full_img_mask.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "256fa90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
       "\n",
       "body, html {\n",
       "  margin: 0;\n",
       "  padding: 0;\n",
       "  width: 100%;\n",
       "}\n",
       "\n",
       "#focontainer-b06f28a2-d39f-4409-9005-4322be21e509 {\n",
       "  position: relative;\n",
       "  height: 800px;\n",
       "  display: block !important;\n",
       "}\n",
       "#foactivate-b06f28a2-d39f-4409-9005-4322be21e509 {\n",
       "  font-weight: bold;\n",
       "  cursor: pointer;\n",
       "  font-size: 24px;\n",
       "  border-radius: 3px;\n",
       "  text-align: center;\n",
       "  padding: 0.5em;\n",
       "  color: rgb(255, 255, 255);\n",
       "  font-family: \"Palanquin\", sans-serif;\n",
       "  position: absolute;\n",
       "  left: 50%;\n",
       "  top: 50%;\n",
       "  width: 160px;\n",
       "  margin-left: -80px;\n",
       "  margin-top: -23px;\n",
       "  background: hsla(210,11%,15%, 0.8);\n",
       "  border: none;\n",
       "}\n",
       "#foactivate-b06f28a2-d39f-4409-9005-4322be21e509:focus {\n",
       "  outline: none;\n",
       "}\n",
       "#fooverlay-b06f28a2-d39f-4409-9005-4322be21e509 {\n",
       "  width: 100%;\n",
       "  height: 100%;\n",
       "  background: hsla(208, 7%, 46%, 0.7);\n",
       "  position: absolute;\n",
       "  top: 0;\n",
       "  left: 0;\n",
       "  display: none;\n",
       "  cursor: pointer;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div id=\"focontainer-b06f28a2-d39f-4409-9005-4322be21e509\">\n",
       "   <div id=\"fooverlay-b06f28a2-d39f-4409-9005-4322be21e509\" style=\"display: none;\">\n",
       "      <button id=\"foactivate-b06f28a2-d39f-4409-9005-4322be21e509\" >Activate</button>\n",
       "   </div>\n",
       "   <img src='data:image/jpeg;base64,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' style=\"width: 100%; max-width: 919px;\"/>\n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "   (function() {\n",
       "     var container = document.getElementById(\"focontainer-b06f28a2-d39f-4409-9005-4322be21e509\");\n",
       "     var overlay = document.getElementById(\"fooverlay-b06f28a2-d39f-4409-9005-4322be21e509\");\n",
       "     fetch(`http://localhost:5151/fiftyone`)\n",
       "     .then(() => {\n",
       "        overlay.addEventListener(\"click\", () => {\n",
       "          fetch(`http://localhost:5151/event`, {\n",
       "            method: \"POST\",\n",
       "            body: JSON.stringify({\n",
       "              event: \"reactivate_notebook_cell\",\n",
       "              data: { subscription: \"b06f28a2-d39f-4409-9005-4322be21e509\" },\n",
       "              subscription: \"b06f28a2-d39f-4409-9005-4322be21e509\"\n",
       "            })\n",
       "          })\n",
       "        });\n",
       "        container.addEventListener(\"mouseenter\", () => overlay.style.display = \"block\");\n",
       "        container.addEventListener(\"mouseleave\", () => overlay.style.display = \"none\");\n",
       "     });\n",
       "   })();\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e51f040a",
   "metadata": {},
   "source": [
    "# Training ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec2c4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    weights = FCN_ResNet50_Weights.DEFAULT\n",
    "    model = fcn_resnet50(weights=weights, classes=num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d3c0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, torch_dataset, torch_dataset_test, num_epochs=4):\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        torch_dataset, batch_size=2, shuffle=False, num_workers=0,\n",
    "        collate_fn=utils.collate_fn\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        torch_dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "        collate_fn=utils.collate_fn\n",
    "    )\n",
    "\n",
    "    device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params, lr=0.001,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size=5,\n",
    "                                                    gamma=0.1)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model=model,\n",
    "                        criterion=criterion,\n",
    "                        optimizer=optimizer, \n",
    "                        data_loader=data_loader,\n",
    "                        lr_scheduler=lr_scheduler,\n",
    "                        device=device, \n",
    "                        epoch=epoch, \n",
    "                        print_freq=10)\n",
    "\n",
    "        evaluate(model=model, data_loader=data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "234e99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.PILToTensor(), transforms.ConvertImageDtype(torch.float)])\n",
    "test_transform = transforms.Compose([transforms.PILToTensor(), transforms.ConvertImageDtype(torch.float)])\n",
    "HRSID_train = HRSIDDataset(dataset_train, transforms=train_transform)\n",
    "HRSID_test = HRSIDDataset(dataset_test, transforms=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "77d45d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ee8edf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n",
      "frame_size (800, 800)\n",
      "mask shape torch.Size([13, 800, 800])\n",
      "frame_size (800, 800)\n",
      "mask shape torch.Size([5, 800, 800])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m do_training(model, HRSID_train, HRSID_test, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[129], line 24\u001b[0m, in \u001b[0;36mdo_training\u001b[0;34m(model, torch_dataset, torch_dataset_test, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m lr_scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer,\n\u001b[1;32m     21\u001b[0m                                                 step_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     22\u001b[0m                                                 gamma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 24\u001b[0m     train_one_epoch(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     25\u001b[0m                     criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m     26\u001b[0m                     optimizer\u001b[39m=\u001b[39;49moptimizer, \n\u001b[1;32m     27\u001b[0m                     data_loader\u001b[39m=\u001b[39;49mdata_loader,\n\u001b[1;32m     28\u001b[0m                     lr_scheduler\u001b[39m=\u001b[39;49mlr_scheduler,\n\u001b[1;32m     29\u001b[0m                     device\u001b[39m=\u001b[39;49mdevice, \n\u001b[1;32m     30\u001b[0m                     epoch\u001b[39m=\u001b[39;49mepoch, \n\u001b[1;32m     31\u001b[0m                     print_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     33\u001b[0m     evaluate(model\u001b[39m=\u001b[39mmodel, data_loader\u001b[39m=\u001b[39mdata_loader_test, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/ENEE439/Capstone/train.py:106\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, data_loader, lr_scheduler, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[1;32m    104\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    105\u001b[0m target \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m target]\n\u001b[0;32m--> 106\u001b[0m masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([i[\u001b[39m'\u001b[39;49m\u001b[39mmasks\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m target])\n\u001b[1;32m    107\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    108\u001b[0m     output \u001b[39m=\u001b[39m model(image)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_training(model, HRSID_train, HRSID_test, num_epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
